# LangExtract API Configuration
LANGEXTRACT_API_KEY=your-gemini-api-key-here

# Model Configuration
DEFAULT_MODEL_ID=gemini-2.5-flash
MAX_CHAR_BUFFER=4000
MAX_WORKERS=4

# Ollama Configuration (for local models)
OLLAMA_HOST=http://localhost:11434

# Output Configuration
OUTPUT_DIR=./output
ENABLE_VISUALIZATIONS=true

# Development Settings
LOG_LEVEL=INFO
ENABLE_DEBUG=false